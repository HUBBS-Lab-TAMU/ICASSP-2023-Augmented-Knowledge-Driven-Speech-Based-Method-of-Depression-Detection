{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42771085",
   "metadata": {},
   "source": [
    "#### train the model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c4e527a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-30T20:05:56.449837Z",
     "iopub.status.busy": "2022-09-30T20:05:56.446184Z",
     "iopub.status.idle": "2022-09-30T20:06:16.765509Z",
     "shell.execute_reply": "2022-09-30T20:06:16.763893Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 138/138 [00:00<00:00, 148.01batch/s]\n",
      "Epoch 2: 100%|██████████| 138/138 [00:01<00:00, 136.12batch/s]\n",
      "Epoch 3: 100%|██████████| 138/138 [00:01<00:00, 130.68batch/s]\n",
      "Epoch 4: 100%|██████████| 138/138 [00:01<00:00, 131.08batch/s]\n",
      "Epoch 5: 100%|██████████| 138/138 [00:01<00:00, 128.07batch/s]\n",
      "Epoch 6: 100%|██████████| 138/138 [00:01<00:00, 132.32batch/s]\n",
      "Epoch 7: 100%|██████████| 138/138 [00:01<00:00, 129.76batch/s]\n",
      "Epoch 8: 100%|██████████| 138/138 [00:01<00:00, 130.39batch/s]\n",
      "Epoch 9: 100%|██████████| 138/138 [00:01<00:00, 128.29batch/s]\n",
      "Epoch 10: 100%|██████████| 138/138 [00:01<00:00, 128.08batch/s]\n"
     ]
    }
   ],
   "source": [
    "# positive 1 depressed\n",
    "# negative 0 non-depressed\n",
    "\n",
    "# import pickle\n",
    "import pickle5 as pickle\n",
    "from model import CNN\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from collections import Counter\n",
    "import torchvision.transforms as transforms\n",
    "import copy\n",
    "\n",
    "import random, os\n",
    "import torch\n",
    "import numpy as np\n",
    "seed = 32\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] =str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic =True\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "label_csv = pd.read_csv('../processed_data/train_split_Depression_AVEC2017.csv')\n",
    "user_list = list(label_csv['Participant_ID'])\n",
    "\n",
    "with open('../processed_data/train_labels.pickle', 'rb') as handle:\n",
    "    train_labels = pickle.load(handle)\n",
    "\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "aug_ratio_pos = 32\n",
    "aug_ratio_neg = 16\n",
    "top_k_reserve = 5\n",
    "marked_uttr = 1\n",
    "# marked_uttr = 0\n",
    "\n",
    "for user in user_list:\n",
    "    feature = np.array(np.load('../processed_data/feature_fc1/'+str(user)+'.npy'))\n",
    "    saliency = list(np.load('../processed_data/saliency/'+str(user)+'.npy'))\n",
    "    # print(saliency)\n",
    "    select_range = range(len(saliency) - 10) if len(saliency) != 10 else [0]\n",
    "    # print(select_range)\n",
    "    aug_ratio = aug_ratio_pos if train_labels[user] else aug_ratio_neg\n",
    "\n",
    "    for i in range(aug_ratio):\n",
    "        start_idx = np.random.choice(select_range, replace=False, size=1)[0]\n",
    "        feature_part = feature[start_idx:start_idx+10,:]\n",
    "        # print(feature_part.shape)\n",
    "        top_idx = np.argsort(saliency[start_idx:start_idx+10])[:top_k_reserve]\n",
    "        remaining_idx = list(set(range(10)) - set(top_idx))\n",
    "        selected_idx = np.random.choice(remaining_idx, replace=False, size=marked_uttr)\n",
    "        if np.random.rand() < 0.5:\n",
    "            for idx in selected_idx:\n",
    "                feature_part[idx,:] = 0.001\n",
    "                # feature_part[idx,:] = np.mean(feature_part[idx,:])\n",
    "        X.append(torch.Tensor(np.transpose(feature_part)))\n",
    "        y.append(train_labels[user])\n",
    "    \n",
    "tensor_y_train = torch.Tensor(np.array(y)).to(torch.float)\n",
    "\n",
    "tensor_X_train = torch.stack((X))\n",
    "\n",
    "\n",
    "trainDataset = TensorDataset(tensor_X_train, tensor_y_train)\n",
    "\n",
    "trainLoader = DataLoader(trainDataset, batch_size=16, shuffle=True)\n",
    "\n",
    "\n",
    "cnn = CNN().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=0.001, weight_decay=0.01)\n",
    "\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "\n",
    "    with tqdm(trainLoader, unit=\"batch\") as tepoch:\n",
    "\n",
    "        for data in tepoch:\n",
    "            tepoch.set_description(f\"Epoch {epoch+1}\")\n",
    "            x, y = data\n",
    "            x = Variable(x).to(device)\n",
    "            y = Variable(y).to(device)\n",
    "\n",
    "            out = cnn(x)\n",
    "            loss = criterion(out, y.long())\n",
    "\n",
    "            _, pred = torch.max(out, 1)\n",
    "\n",
    "            num_correct = (pred == y).sum()\n",
    "            running_acc += num_correct.item()\n",
    "            running_loss = running_loss + loss.detach()*y.size(0)\n",
    "\n",
    "            acc = (pred == y).float().mean()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f961e0",
   "metadata": {},
   "source": [
    "#### validate the trained model on the validation set\n",
    "##### we applied a weighted voting based on the length of a window only for window size is 10. This slighly helped with the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbf95998",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-30T20:06:16.801517Z",
     "iopub.status.busy": "2022-09-30T20:06:16.799954Z",
     "iopub.status.idle": "2022-09-30T20:06:16.911153Z",
     "shell.execute_reply": "2022-09-30T20:06:16.909837Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.77        23\n",
      "           1       0.55      0.50      0.52        12\n",
      "\n",
      "    accuracy                           0.69        35\n",
      "   macro avg       0.65      0.64      0.64        35\n",
      "weighted avg       0.68      0.69      0.68        35\n",
      "\n",
      "[[18  5]\n",
      " [ 6  6]]\n"
     ]
    }
   ],
   "source": [
    "sample_length = 10\n",
    "overlap = 0\n",
    "label_csv = pd.read_csv('../processed_data/dev_split_Depression_AVEC2017.csv')\n",
    "user_list = list(label_csv['Participant_ID'])\n",
    "\n",
    "with open('../processed_data/dev_labels.pickle', 'rb') as handle:\n",
    "    dev_labels = pickle.load(handle)\n",
    "\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "all_length = []\n",
    "all_saliency = []\n",
    "user_names = []\n",
    "for user in user_list:\n",
    "    sorted_feature = np.array(np.load('../processed_data/feature_fc1/'+str(user)+'.npy'))\n",
    "    length = np.load('../processed_data/length/'+str(user)+'.npy')\n",
    "    saliency = list(np.load('../processed_data/saliency/'+str(user)+'.npy'))\n",
    "\n",
    "    starting_idx = 0\n",
    "    x_tmp = []\n",
    "    saliency_tmp = []\n",
    "    length_tmp = []\n",
    "    while starting_idx + sample_length < len(length):\n",
    "        sorted_feature_tmp = sorted_feature[starting_idx:starting_idx+sample_length]\n",
    "        sorted_feature_tmp = torch.Tensor(np.transpose(sorted_feature_tmp))\n",
    "        x_tmp.append(sorted_feature_tmp)\n",
    "        saliency_tmp.append(np.sum(saliency[starting_idx:starting_idx+sample_length]))\n",
    "        length_tmp.append(np.sum(length[starting_idx:starting_idx+sample_length]))\n",
    "        starting_idx = starting_idx + sample_length-overlap\n",
    "\n",
    "    X.append(torch.stack((x_tmp)))\n",
    "    y.append(dev_labels[user])\n",
    "\n",
    "    all_saliency.append(saliency_tmp)\n",
    "    all_length.append(length_tmp)\n",
    "\n",
    "    user_names.append(user)\n",
    "    \n",
    "\n",
    "weight_ref = all_length\n",
    "    \n",
    "\n",
    "cnn.eval()\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for i in range(0, len(X)):\n",
    "    y_true.append(y[i])\n",
    "    x = Variable(X[i]).to(device)\n",
    "    out = F.softmax(cnn(x), dim=1)\n",
    "    prob_tmp = out.data.cpu().numpy()\n",
    "    tmp = np.array(weight_ref[i])\n",
    "    prob_tmp = prob_tmp * tmp.reshape((tmp.size, 1))\n",
    "    prob_tmp = np.sum(prob_tmp, axis=0)\n",
    "\n",
    "    prob = prob_tmp / out.shape[0]\n",
    "    y_pred.append(np.argmax(prob, axis=0))\n",
    "\n",
    "\n",
    "print(classification_report(y_true, y_pred, zero_division=0))\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e294ff",
   "metadata": {},
   "source": [
    "#### provide the running environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17b32b4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-30T20:06:16.932413Z",
     "iopub.status.busy": "2022-09-30T20:06:16.930784Z",
     "iopub.status.idle": "2022-09-30T20:06:17.712170Z",
     "shell.execute_reply": "2022-09-30T20:06:17.710820Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------  --------------------------------------------------\n",
      "sys.platform           linux\n",
      "Python                 3.6.9 (default, Jun 29 2022, 11:45:57) [GCC 8.4.0]\n",
      "Numpy                  1.19.5\n",
      "DETECTRON2_ENV_MODULE  <not set>\n",
      "PyTorch                1.10.2+cu113\n",
      "PyTorch Debug Build    False\n",
      "torchvision            0.11.3+cu113\n",
      "CUDA available         True\n",
      "GPU 0,1                NVIDIA RTX A6000\n",
      "CUDA_HOME              /usr/local/cuda\n",
      "NVCC                   Build cuda_11.2.r11.2/compiler.29618528_0\n",
      "Pillow                 8.4.0\n",
      "---------------------  --------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX512\n",
      "  - CUDA Runtime 11.3\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.2\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import PIL\n",
    "import torch\n",
    "import torchvision\n",
    "from tabulate import tabulate\n",
    "\n",
    "__all__ = [\"collect_env_info\"]\n",
    "\n",
    "def get_env_module():\n",
    "    var_name = \"DETECTRON2_ENV_MODULE\"\n",
    "    return var_name, os.environ.get(var_name, \"<not set>\")\n",
    "\n",
    "\n",
    "def collect_torch_env():\n",
    "    try:\n",
    "        import torch.__config__\n",
    "\n",
    "        return torch.__config__.show()\n",
    "    except ImportError:\n",
    "        # compatible with older versions of pytorch\n",
    "        from torch.utils.collect_env import get_pretty_env_info\n",
    "\n",
    "        return get_pretty_env_info()\n",
    "\n",
    "\n",
    "def collect_env_info():\n",
    "    data = []\n",
    "    data.append((\"sys.platform\", sys.platform))\n",
    "    data.append((\"Python\", sys.version.replace(\"\\n\", \"\")))\n",
    "    data.append((\"Numpy\", np.__version__))\n",
    "\n",
    "    data.append(get_env_module())\n",
    "    data.append((\"PyTorch\", torch.__version__))\n",
    "    data.append((\"PyTorch Debug Build\", torch.version.debug))\n",
    "    try:\n",
    "        data.append((\"torchvision\", torchvision.__version__))\n",
    "    except AttributeError:\n",
    "        data.append((\"torchvision\", \"unknown\"))\n",
    "\n",
    "    has_cuda = torch.cuda.is_available()\n",
    "    data.append((\"CUDA available\", has_cuda))\n",
    "    if has_cuda:\n",
    "        devices = defaultdict(list)\n",
    "        for k in range(torch.cuda.device_count()):\n",
    "            devices[torch.cuda.get_device_name(k)].append(str(k))\n",
    "        for name, devids in devices.items():\n",
    "            data.append((\"GPU \" + \",\".join(devids), name))\n",
    "\n",
    "        from torch.utils.cpp_extension import CUDA_HOME\n",
    "\n",
    "        data.append((\"CUDA_HOME\", str(CUDA_HOME)))\n",
    "\n",
    "        if CUDA_HOME is not None and os.path.isdir(CUDA_HOME):\n",
    "            try:\n",
    "                nvcc = os.path.join(CUDA_HOME, \"bin\", \"nvcc\")\n",
    "                nvcc = subprocess.check_output(\"'{}' -V | tail -n1\".format(nvcc), shell=True)\n",
    "                nvcc = nvcc.decode(\"utf-8\").strip()\n",
    "            except subprocess.SubprocessError:\n",
    "                nvcc = \"Not Available\"\n",
    "            data.append((\"NVCC\", nvcc))\n",
    "\n",
    "        cuda_arch_list = os.environ.get(\"TORCH_CUDA_ARCH_LIST\", None)\n",
    "        if cuda_arch_list:\n",
    "            data.append((\"TORCH_CUDA_ARCH_LIST\", cuda_arch_list))\n",
    "    data.append((\"Pillow\", PIL.__version__))\n",
    "\n",
    "    try:\n",
    "        import cv2\n",
    "\n",
    "        data.append((\"cv2\", cv2.__version__))\n",
    "    except ImportError:\n",
    "        pass\n",
    "    env_str = tabulate(data) + \"\\n\"\n",
    "    env_str += collect_torch_env()\n",
    "    return env_str\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(collect_env_info())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
